{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b9f202-9815-4520-b7f0-d604b9792bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mode = 'bart'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f5340-4a6c-49e8-aa2e-41f8a22d3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mode = 't5'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d1869-1aef-464d-ba65-a9618988f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(encoder_output: torch.Tensor, target_snr_db: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adds noise to the encoder output based on a target SNR in dB.\n",
    "\n",
    "    Args:\n",
    "        encoder_output (torch.Tensor): The encoder's output (last_hidden_state).\n",
    "        target_snr_db (float): The desired signal-to-noise ratio in dB.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Encoder output with added noise.\n",
    "    \"\"\"\n",
    "    # Convert SNR from dB to linear scale\n",
    "    target_snr_linear = 10 ** (target_snr_db / 10)\n",
    "    \n",
    "    # Calculate power of the signal\n",
    "    signal_power = torch.mean(encoder_output ** 2)\n",
    "    \n",
    "    # Calculate required noise power for the target SNR\n",
    "    noise_power = signal_power / target_snr_linear\n",
    "    noise = torch.randn_like(encoder_output) * torch.sqrt(noise_power)\n",
    "    \n",
    "    # Add noise to the encoder output\n",
    "    noisy_encoder_output = encoder_output + noise\n",
    "    return noisy_encoder_output\n",
    "\n",
    "def generate_with_embeddings(input_text: str, encoder_outputs: torch.Tensor = None, mode: str = 't5') -> (str, torch.Tensor, list):\n",
    "    \"\"\"\n",
    "    Generates text from input and returns both generated text and decoder embeddings.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): Input text for the model.\n",
    "        encoder_outputs (torch.Tensor, optional): Custom encoder outputs to be fed into the decoder.\n",
    "        mode (str): The mode of the model, either 't5' or 'bart'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, torch.Tensor, list]: Generated text, decoder embeddings for each token in the output sequence, and decoded tokens.\n",
    "    \"\"\"\n",
    "    # Encode input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Pass through encoder if no custom encoder outputs provided\n",
    "    if encoder_outputs is None:\n",
    "        if mode == 't5':\n",
    "            encoder_outputs = model.encoder(input_ids=inputs.input_ids)\n",
    "        elif mode == 'bart':\n",
    "            encoder_outputs = model.model.encoder(input_ids=inputs.input_ids)\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be 't5' or 'bart'\")\n",
    "    else:\n",
    "        # Copy the encoder_outputs to prevent accumulation\n",
    "        encoder_outputs = BaseModelOutput(last_hidden_state=encoder_outputs.last_hidden_state.clone())\n",
    "    \n",
    "    # Generate with embeddings output\n",
    "    outputs = model.generate(\n",
    "        input_ids=None,  # Set None to use encoder_outputs\n",
    "        encoder_outputs=encoder_outputs,\n",
    "        output_hidden_states=True,\n",
    "        return_dict_in_generate=True,\n",
    "        max_length=500,\n",
    "        min_length=10,\n",
    "        do_sample=True,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    # Retrieve generated token IDs and decode to text\n",
    "    generated_ids = outputs.sequences\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Collect the last decoder hidden states as embeddings\n",
    "    last_column = [row[-1] for row in outputs.decoder_hidden_states]\n",
    "    decoder_embeddings = torch.stack(last_column).squeeze()  # squeeze() to eliminate unnecessary dimensions\n",
    "    \n",
    "    # Decode embeddings back to tokens\n",
    "    decoded_tokens = [tokenizer.decode([token]) for token in generated_ids[0]]\n",
    "\n",
    "    return generated_text, decoder_embeddings, decoded_tokens\n",
    "\n",
    "def align_tensors(tensor_a: torch.Tensor, tensor_b: torch.Tensor, mode: str = \"truncate\") -> (torch.Tensor, torch.Tensor):\n",
    "    \"\"\"\n",
    "    Aligns two tensors along the first dimension by either truncating or padding.\n",
    "\n",
    "    Args:\n",
    "        tensor_a (torch.Tensor): The first tensor.\n",
    "        tensor_b (torch.Tensor): The second tensor.\n",
    "        mode (str): The alignment mode, either \"truncate\" or \"pad\".\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: The two tensors aligned along the first dimension.\n",
    "    \"\"\"\n",
    "    # Get the first dimension sizes\n",
    "    m, n = tensor_a.size(0), tensor_b.size(0)\n",
    "\n",
    "    if mode == \"truncate\":\n",
    "        # Truncate to the minimum length along the first dimension\n",
    "        min_rows = min(m, n)\n",
    "        tensor_a = tensor_a[:min_rows]\n",
    "        tensor_b = tensor_b[:min_rows]\n",
    "\n",
    "    elif mode == \"pad\":\n",
    "        # Pad to the maximum length along the first dimension\n",
    "        max_rows = max(m, n)\n",
    "        if m < max_rows:\n",
    "            padding = torch.zeros((max_rows - m, *tensor_a.shape[1:]), device=tensor_a.device)\n",
    "            tensor_a = torch.cat([tensor_a, padding], dim=0)\n",
    "        if n < max_rows:\n",
    "            padding = torch.zeros((max_rows - n, *tensor_b.shape[1:]), device=tensor_b.device)\n",
    "            tensor_b = torch.cat([tensor_b, padding], dim=0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'truncate' or 'pad'\")\n",
    "\n",
    "    return tensor_a, tensor_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
