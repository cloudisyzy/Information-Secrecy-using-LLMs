{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf8bc87-4441-4905-a14e-2c916b8061b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "import torch\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561adc1a-59c8-4ca3-829d-41ef80a888ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"facebook/bart-base\" # Recommend this one if your computer is okay with larger models\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e088c67-2710-4834-a9d7-0c2f27a3fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(encoder_output, target_snr_db):\n",
    "    \"\"\"\n",
    "    Add noise to the encoder output based on a target SNR in dB.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoder_output: torch.Tensor, the encoder's output (last_hidden_state).\n",
    "    - target_snr_db: float, the desired signal-to-noise ratio in dB.\n",
    "    \n",
    "    Returns:\n",
    "    - noisy_encoder_output: torch.Tensor, encoder output with added noise.\n",
    "    \"\"\"\n",
    "    # Convert SNR from dB to linear scale\n",
    "    target_snr_linear = 10 ** (target_snr_db / 10)\n",
    "    \n",
    "    # Calculate power of the signal\n",
    "    signal_power = torch.mean(encoder_output ** 2)\n",
    "    \n",
    "    # Calculate required noise power for the target SNR\n",
    "    noise_power = signal_power / target_snr_linear\n",
    "    noise = torch.randn_like(encoder_output) * torch.sqrt(noise_power)\n",
    "    \n",
    "    # Add noise to the encoder output\n",
    "    noisy_encoder_output = encoder_output + noise\n",
    "    return noisy_encoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f8c3d9-8887-4259-b7dc-94b5003d2ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px;'>Tranlate English to Deutsche: How are you feature and is a subject?</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Noise:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px; font-family:\"Comic Sans MS\", cursive;'> Wie sind Sie Feature und ist ein Thema?</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise (SNR = 3 dB):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px; font-family:\"Comic Sans MS\", cursive;'> Mit welchem Feature und welcher Objekt?</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input_text = \"Tranlate English to Deutsche: This is an experimental feature and is a subject to change at a moment's notice.\"\n",
    "input_text = \"Tranlate English to Deutsche: How are you feature and is a subject?\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# Get encoder output without noise\n",
    "with torch.no_grad():\n",
    "    encoder_outputs = model.encoder(input_ids=input_ids) # BART\n",
    "    # encoder_outputs = model.encoder(input_ids=input_ids) # T5\n",
    "\n",
    "# Generate output without noise\n",
    "baseline_outputs = model.generate(\n",
    "    input_ids=None,\n",
    "    encoder_outputs=encoder_outputs,\n",
    "    output_hidden_states=True,\n",
    "    return_dict_in_generate=True,\n",
    "    max_length=500,\n",
    "    do_sample=True,\n",
    "    temperature=0.1\n",
    ")\n",
    "baseline_text = tokenizer.decode(baseline_outputs.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "# Add noise with a target SNR and generate noisy output\n",
    "target_snr = 3  # Set target SNR\n",
    "noisy_encoder_output = add_noise_with_snr(encoder_outputs.last_hidden_state, target_snr)\n",
    "modified_encoder_outputs = BaseModelOutput(last_hidden_state=noisy_encoder_output)\n",
    "\n",
    "# Generate output with the noisy encoder output\n",
    "noisy_outputs = model.generate(\n",
    "    input_ids=None,\n",
    "    encoder_outputs=modified_encoder_outputs,\n",
    "    output_hidden_states=True,\n",
    "    return_dict_in_generate=True,\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    temperature=0.1\n",
    ")\n",
    "noisy_text = tokenizer.decode(noisy_outputs.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "# Display both outputs\n",
    "display(HTML(f\"<p style='font-size:15px;'>{input_text}</p>\"))\n",
    "print('Without Noise:')\n",
    "display(HTML(f\"<p style='font-size:20px; font-family:\\\"Comic Sans MS\\\", cursive;'> {baseline_text}</p>\"))\n",
    "print(f'With Noise (SNR = {target_snr} dB):')\n",
    "display(HTML(f\"<p style='font-size:20px; font-family:\\\"Comic Sans MS\\\", cursive;'> {noisy_text}</p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b54e5899-d3e5-4e00-a454-f117ba3be020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_outputs.sequences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de7903d-f703-4885-a8c5-cac2740f6eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1024])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_hidden_states = baseline_outputs.decoder_hidden_states\n",
    "last_layer_hidden_states = torch.cat(\n",
    "    [decoder_hidden_states[token_idx][-1] for token_idx in range(len(decoder_hidden_states))],\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "last_layer_hidden_states.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb8737f8-5f43-4b93-9fbb-de3a060881b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1024])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_column = [row[-1] for row in baseline_outputs.decoder_hidden_states]\n",
    "decoder_embeddings = torch.stack(last_column).squeeze()\n",
    "decoder_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc271639-ebe5-40af-8573-b0dd271d34f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output = torch.stack(last_column)\n",
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2deedd-2b7b-47d1-abd1-75618a5a914f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.2577e-01,  7.0460e-02, -6.4927e-02,  ...,  2.2854e-01,\n",
       "           -3.5367e+00,  2.9031e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.1239e-03, -1.8696e-02,  1.0281e-01,  ...,  5.3043e-02,\n",
       "           -2.7600e+00,  1.2889e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.4533e-01,  6.7206e-02,  3.9925e-02,  ...,  9.7330e-03,\n",
       "           -2.8842e+00,  1.2087e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1294e-03,  1.3861e-01,  2.7731e-02,  ...,  9.4162e-02,\n",
       "           -2.8283e+00,  3.9442e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.8444e-02,  1.3694e-01,  3.3259e-03,  ...,  2.4101e-01,\n",
       "           -2.8714e+00,  9.5911e-03]]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c99be3fc-0e06-4c03-8b1d-50dcca77ef34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0684,  0.1369,  0.0033,  ...,  0.2410, -2.8714,  0.0096]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_outputs.decoder_hidden_states[-1][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
