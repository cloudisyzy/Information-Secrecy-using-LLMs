{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartModel\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\tokenizer.json\n",
      "loading configuration file config.json from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\sreya\\.cache\\huggingface\\hub\\models--facebook--bart-large\\snapshots\\cb48c1365bd826bd521f650dc2e0940aee54720c\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"\"\"\n",
    "Welcome to our online coding bootcamp program! \n",
    "Whether you're a complete beginner or looking to improve your programming skills, this course is designed for you. \n",
    "Throughout the course, you will learn essential coding languages such as Python and JavaScript. \n",
    "Our instructors will guide you through interactive projects and provide real-time feedback. \n",
    "Each student will receive a certificate of completion at the end of the program. \n",
    "The total cost for the bootcamp is $150, which includes all learning materials.\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"\"\"\n",
    "Welcome to our online <mask> bootcamp program! \n",
    "Whether you're a complete beginner or looking to <mask> your programming skills, this course is designed for you. \n",
    "Throughout the course, you will learn essential <mask> such as Python and JavaScript. \n",
    "Our instructors will guide you through interactive projects and provide real-time <mask>. \n",
    "Each student will receive a certificate of completion at the end of the <mask>. \n",
    "The total cost for the bootcamp is $150, which <mask> all learning materials.\n",
    "\"\"\".replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 94])\n"
     ]
    }
   ],
   "source": [
    "# return_tensors returns the tokenizer output as pytorch tensors\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[-0.0008,  0.0308,  0.0059,  ...,  0.0247, -0.0319,  0.0094],\n",
      "         [-0.0300, -0.0781,  0.0877,  ..., -0.2132,  0.0201,  0.0499],\n",
      "         [-0.0061,  0.1724,  0.1160,  ..., -0.1056, -0.0867, -0.0710],\n",
      "         ...,\n",
      "         [-0.0306, -0.1893, -0.0245,  ..., -0.1376, -0.0109, -0.0656],\n",
      "         [ 0.0008,  0.0165,  0.0067,  ...,  0.0070, -0.0087, -0.0018],\n",
      "         [ 0.1437,  0.2210,  0.0996,  ..., -0.0200, -0.0611,  0.0710]]],\n",
      "       device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    encoder_outputs = model.model.encoder(input_ids=input_ids)\n",
    "\n",
    "print(encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2,     0, 25194,     7,    84,   804,  8326,  9759, 21669,   586,\n",
      "          328,  5994,    47,   214,    10,  1498, 37239,    50,   546,     7,\n",
      "         1477,   110,  8326,  2417,     6,    42,   768,    16,  1887,    13,\n",
      "           47,     4, 13231,     5,   768,     6,    47,    40,  1532,  4499,\n",
      "         8326,  2417,   215,    25, 31886,     8, 18434,     4,  1541, 25508,\n",
      "           40,  4704,    47,   149, 10813,  1377,     8,   694,   588,    12,\n",
      "          958,     4,  4028,  1294,    40,  1325,    10, 10921,     9,  5687,\n",
      "           23,     5,   253,     9,     5,     4,    20,   746,   701,    13,\n",
      "            5,  9759, 21669,    16,    68,  6115,     6,    61,  1171, 12263,\n",
      "            6,  2799,     6,     8,    70,  2239,  3183,     4,     2],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "no_noise_outputs = model.generate(\n",
    "    input_ids = None,\n",
    "    encoder_outputs = encoder_outputs,\n",
    "    max_length = 200,\n",
    "    min_length = 10,\n",
    "    do_sample = True,\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "print(no_noise_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our online programming bootcamp program! Whether you're a complete beginner or looking to improve your programming skills, this course is designed for you. Throughout the course, you will learn essential programming skills such as Python and JavaScript. Our instructors will guide you through interactive projects and provide real-time. Each student will receive a certificate of completion at the end of the. The total cost for the bootcamp is $150, which includes tuition, books, and all learning materials.\n"
     ]
    }
   ],
   "source": [
    "no_noise_text_output = tokenizer.decode(no_noise_outputs[0], skip_special_tokens=True)\n",
    "print(no_noise_text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px; font-family:\"Comic Sans MS\", cursive;'> \n",
       "Welcome to our online coding bootcamp program! \n",
       "Whether you're a complete beginner or looking to improve your programming skills, this course is designed for you. \n",
       "Throughout the course, you will learn essential coding languages such as Python and JavaScript. \n",
       "Our instructors will guide you through interactive projects and provide real-time feedback. \n",
       "Each student will receive a certificate of completion at the end of the program. \n",
       "The total cost for the bootcamp is $150, which includes all learning materials.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Without Noise:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px; font-family:\"Comic Sans MS\", cursive;'>Welcome to our online programming bootcamp program! Whether you're a complete beginner or looking to improve your programming skills, this course is designed for you. Throughout the course, you will learn essential programming skills such as Python and JavaScript. Our instructors will guide you through interactive projects and provide real-time. Each student will receive a certificate of completion at the end of the. The total cost for the bootcamp is $150, which includes tuition, books, and all learning materials.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original Text:')\n",
    "display(HTML(f\"<p style='font-size:15px; font-family:\\\"Comic Sans MS\\\", cursive;'> {original_text}</p>\"))\n",
    "print('\\n')\n",
    "\n",
    "print('Without Noise:')\n",
    "display(HTML(f\"<p style='font-size:15px; font-family:\\\"Comic Sans MS\\\", cursive;'>{no_noise_text_output}</p>\"))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Masked tokens which are at end of the sentence are not being filled in whereas mid of sentence tokens are**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
