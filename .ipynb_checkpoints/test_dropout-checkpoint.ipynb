{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779a0a02-2b70-4000-b70c-9c981e38c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79c692d-1ec0-417c-acc3-69273fccbfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Automatically choose (prefer NVIDIA GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify model name\n",
    "model_name = \"facebook/bart-base\"\n",
    "tokenizer_bart = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Specify model name\n",
    "summarizer_name = \"Falconsai/text_summarization\"\n",
    "tokenizer_sum = T5Tokenizer.from_pretrained(summarizer_name)\n",
    "summarizer = T5ForConditionalGeneration.from_pretrained(summarizer_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6073a4b6-d0a9-42cc-92d7-bc0bf02f9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr_new(encoder_output, noise_type='gaussian', target_snr_db=3, dropout_rate=0.4, sp_thresh=0.4):\n",
    "    \"\"\"\n",
    "    Add noise to the encoder output based on a target SNR in dB.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoder_output: torch.Tensor, the encoder's output (last_hidden_state).\n",
    "    - noise_type: string, determines what kind of noise is added.\n",
    "    - target_snr_db: float, the desired signal-to-noise ratio in dB for awgn and dropout.\n",
    "    - dropout_rate: float, range: [0,1], default rate for dropout noise (not used here).\n",
    "    - sp_thresh: float, range: [0,1], determines the threshold for salt-and-pepper noise.\n",
    "    \n",
    "    Returns:\n",
    "    - noisy_encoder_output: torch.Tensor, encoder output with added noise.\n",
    "    \"\"\"\n",
    "    signal_power = torch.mean(encoder_output ** 2)\n",
    "    target_snr = 10 ** (target_snr_db / 10)\n",
    "    noise_power = signal_power / target_snr\n",
    "\n",
    "    if noise_type.lower() == 'gaussian':\n",
    "        # Generate Gaussian noise\n",
    "        noise = torch.randn_like(encoder_output) * torch.sqrt(noise_power)\n",
    "        return encoder_output + noise\n",
    "\n",
    "    elif noise_type.lower() == 'dropout':\n",
    "        # Compute dropout probability p based on SNR\n",
    "        signal_power = torch.mean(encoder_output ** 2)\n",
    "        target_snr_linear = 10 ** (target_snr_db / 10)\n",
    "        noise_power = signal_power / target_snr_linear\n",
    "        p = 1 / target_snr_linear\n",
    "\n",
    "        # Create a mask with elements set to zero with probability p\n",
    "        random_tensor = torch.rand_like(encoder_output)\n",
    "        mask = random_tensor >= p  # Retain elements with probability (1 - p)\n",
    "\n",
    "        # Apply the mask to the encoder output without scaling\n",
    "        noisy_encoder_output = encoder_output * mask.float()\n",
    "        return noisy_encoder_output\n",
    "\n",
    "    elif noise_type.lower() == 'saltpepper':\n",
    "        mask = torch.rand_like(encoder_output) < sp_thresh  # The greater the sp_thresh, more noise is added\n",
    "        salt = torch.max(encoder_output)\n",
    "        pepper = torch.min(encoder_output)\n",
    "        noise = torch.where(torch.rand_like(encoder_output) < 0.5, salt, pepper)\n",
    "        noised_enc_output = torch.where(mask, noise, encoder_output)\n",
    "        return noised_enc_output\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported Noise Type. Choose between 'gaussian', 'dropout', 'saltpepper'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "731d7573-cfc6-4634-a39a-1e28f57e91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"\"\"\n",
    "Beginners BBQ Class Taking Place in Missoula! \n",
    "Do you want to get better at making delicious BBQ?\n",
    "You will have the opportunity, put this on your calendar now. \n",
    "Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. \n",
    "He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. \n",
    "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. \n",
    "The cost to be in the class is $35 per person, and for spectators it is free. \n",
    "Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
    "\"\"\".replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03d92c4-8c12-44fd-83c9-d2e98120d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beginners BBQ Class Taking Place in Missoula! Do you want to get better at making delicious BBQ?You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will <mask> teaching a beginner level class for everyone who wants to get better with their culinary <mask> He will teach you everything you need <mask> know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and <mask> plus smoker and fire information. The <mask> to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each <mask> that is prepared.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = masking(original_text, 0.05)\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cfdb6bd-fec6-4f8b-abbd-435cdc8a8f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.3971e-02,  7.4056e-03, -2.3095e-03,  ...,  1.1116e-02,\n",
      "          -3.7404e-04, -8.5138e-03],\n",
      "         [ 9.9033e-02,  7.6711e-02, -4.8507e-03,  ..., -4.1736e-01,\n",
      "          -4.1664e-01,  1.8059e-01],\n",
      "         [-1.1457e-01,  9.9002e-02, -2.5445e-01,  ..., -3.9337e-01,\n",
      "           9.2368e-03, -4.2570e-01],\n",
      "         ...,\n",
      "         [-2.4610e-01,  1.4487e-01, -3.4231e-02,  ..., -2.2883e-01,\n",
      "          -5.8550e-03,  1.7179e-02],\n",
      "         [ 2.2376e-01,  8.4899e-03,  2.1352e-01,  ...,  1.9566e-02,\n",
      "          -3.0446e-01,  5.8538e-02],\n",
      "         [ 1.8972e-01, -2.7188e-02,  4.6234e-01,  ...,  1.6946e-02,\n",
      "          -3.5427e-01,  2.8271e-01]]], device='cuda:0')\n",
      "Beginners BBQ Class Taking Place in Missoula! Do you want to get better at making delicious BBQ?You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get good with their culinary skills! He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and more, plus smoker and fire information. The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each item that is prepared.\n",
      "BBQ Class Taking Place in Missoula! The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each item that is prepared.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer_bart(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "with torch.no_grad():\n",
    "    encoder_outputs = model.model.encoder(input_ids=input_ids)\n",
    "\n",
    "target_snr = 50\n",
    "# add noise\n",
    "noisy_encoder_output = add_noise_with_snr_new(\n",
    "    encoder_output = encoder_outputs.last_hidden_state,\n",
    "    noise_type = \"gaussian\",\n",
    "    target_snr_db = target_snr,\n",
    "    dropout_rate = 0,\n",
    "    sp_thresh = 0\n",
    ")\n",
    "modified_encoder_outputs = BaseModelOutput(last_hidden_state=noisy_encoder_output)\n",
    "print(noisy_encoder_output)\n",
    "\n",
    "# first LLM\n",
    "noisy_outputs = model.generate(input_ids=None, encoder_outputs=modified_encoder_outputs, max_length=300, min_length=100, \n",
    "                            num_beams=15, do_sample=True, temperature=1.5, early_stopping=True)\n",
    "noisy_text = tokenizer_bart.decode(noisy_outputs[0], skip_special_tokens=True)\n",
    "print(noisy_text)\n",
    "\n",
    "# second LLM\n",
    "noisy_ids = tokenizer_sum('Summarize:' + noisy_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "with torch.no_grad():\n",
    "    noisy_encoder_outputs = summarizer.encoder(input_ids=noisy_ids)\n",
    "noisy_sum_output = summarizer.generate(input_ids=None, encoder_outputs=noisy_encoder_outputs, max_length=70, output_hidden_states=True, \n",
    "                                       num_beams=15, return_dict_in_generate=True, do_sample=True, temperature=0.1)\n",
    "noisy_summary = tokenizer_sum.decode(noisy_sum_output.sequences[0], skip_special_tokens=True)\n",
    "print(noisy_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53323b12-1c41-4916-a654-f7323149e75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 159, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_encoder_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb4fd3a-b1c6-4a27-84f7-6a4745f27cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n",
      "The second is that there is no such thing as a free lunch. The third is that it is extremely expensive.Finally, there is the fourth. The fourth is that I don't believe in free lunches. I believe in a healthy diet.I'm not a fan of the term \"free lunch.\" I think it's a misnomer. It's more like \"free\" than \"free.\"The fifth is the fact that I'm not sure what to call it. I just know it's not free.The sixth is that my children are growing up. I'm getting older. I can't help it.I've been doing this for years. Now, I've got to go.The seventh is that we're going to be able to talk.I'll be honest. I didn't want to. I was afraid. I wanted to.But I did.And now.It's time.Here's the thing. We've been here before.In fact, we've been there before.But now. Now.Now.Including.The first.The second.S.A.D.C.E.N.T.R.I.M.G.B.SThe third.And finally.The fourth.Finally.The fifth.The last.And the sixth.And last.All.The final.The five.The six.The seven.The eight.The nine.The ten.The eleven.The\n",
      "I.M.G.B.SThe third is that there is no such thing as a free lunch. The third is that it is extremely expensive.Finally, there is the fourth.I don't believe in free lunches.I believe in a healthy diet.I believe in a healthy diet\n"
     ]
    }
   ],
   "source": [
    "# rand_encoder_output = 2 * torch.rand([1, 100, 1024]) - 1\n",
    "# rand_encoder_output = torch.ones([1, 100, 1024])\n",
    "# rand_encoder_output = - torch.ones([1, 100, 1024])\n",
    "rand_encoder_output = torch.zeros([1, 100, 1024])\n",
    "rand_encoder_output = rand_encoder_output.cuda()\n",
    "modified_encoder_outputs = BaseModelOutput(last_hidden_state=rand_encoder_output)\n",
    "print(rand_encoder_output)\n",
    "\n",
    "# first LLM\n",
    "noisy_outputs = model.generate(input_ids=None, encoder_outputs=modified_encoder_outputs, max_length=300, min_length=100, \n",
    "                            num_beams=15, do_sample=True, temperature=1.5, early_stopping=True)\n",
    "noisy_text = tokenizer_bart.decode(noisy_outputs[0], skip_special_tokens=True)\n",
    "print(noisy_text)\n",
    "\n",
    "# second LLM\n",
    "noisy_ids = tokenizer_sum(noisy_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "with torch.no_grad():\n",
    "    noisy_encoder_outputs = summarizer.encoder(input_ids=noisy_ids)\n",
    "noisy_sum_output = summarizer.generate(input_ids=None, encoder_outputs=noisy_encoder_outputs, max_length=70, output_hidden_states=True,\n",
    "                                    return_dict_in_generate=True, do_sample=True, temperature=0.1)\n",
    "noisy_summary = tokenizer_sum.decode(noisy_sum_output.sequences[0], skip_special_tokens=True)\n",
    "print(noisy_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f444db5-d6e3-48ad-8c1e-454d2eb5e4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
