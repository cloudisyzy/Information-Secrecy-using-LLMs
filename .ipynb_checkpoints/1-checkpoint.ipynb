{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9e9fc-95ef-4401-856e-b71eef712840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "mode = 'bart'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5044d44e-5e3a-4a38-94c0-3a1b86862cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "mode = 't5'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60550564-838e-4bd4-be21-2992e99e6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(encoder_output: torch.Tensor, target_snr_db: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adds noise to the encoder output based on a target SNR in dB.\n",
    "\n",
    "    Args:\n",
    "        encoder_output (torch.Tensor): The encoder's output (last_hidden_state).\n",
    "        target_snr_db (float): The desired signal-to-noise ratio in dB.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Encoder output with added noise.\n",
    "    \"\"\"\n",
    "    # Convert SNR from dB to linear scale\n",
    "    target_snr_linear = 10 ** (target_snr_db / 10)\n",
    "    \n",
    "    # Calculate power of the signal\n",
    "    signal_power = torch.mean(encoder_output ** 2)\n",
    "    \n",
    "    # Calculate required noise power for the target SNR\n",
    "    noise_power = signal_power / target_snr_linear\n",
    "    noise = torch.randn_like(encoder_output) * torch.sqrt(noise_power)\n",
    "    \n",
    "    # Add noise to the encoder output\n",
    "    noisy_encoder_output = encoder_output + noise\n",
    "    return noisy_encoder_output\n",
    "\n",
    "def generate_with_embeddings(input_text: str, encoder_outputs: torch.Tensor = None, mode: str = 't5') -> (str, torch.Tensor, list):\n",
    "    \"\"\"\n",
    "    Generates text from input and returns both generated text and decoder embeddings.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): Input text for the model.\n",
    "        encoder_outputs (torch.Tensor, optional): Custom encoder outputs to be fed into the decoder.\n",
    "        mode (str): The mode of the model, either 't5' or 'bart'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, torch.Tensor, list]: Generated text, decoder embeddings for each token in the output sequence, and decoded tokens.\n",
    "    \"\"\"\n",
    "    # Encode input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Pass through encoder if no custom encoder outputs provided\n",
    "    if encoder_outputs is None:\n",
    "        if mode == 't5':\n",
    "            encoder_outputs = model.encoder(input_ids=inputs.input_ids)\n",
    "        elif mode == 'bart':\n",
    "            encoder_outputs = model.model.encoder(input_ids=inputs.input_ids)\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be 't5' or 'bart'\")\n",
    "    else:\n",
    "        # Copy the encoder_outputs to prevent accumulation (ChatGPT tells me to use clone(), otherwise the shape will mismatch later)\n",
    "        encoder_outputs = BaseModelOutput(last_hidden_state=encoder_outputs.last_hidden_state.clone())\n",
    "    \n",
    "    # Generate with embeddings output\n",
    "    outputs = model.generate(\n",
    "        input_ids=None,  # Set None to use encoder_outputs\n",
    "        encoder_outputs=encoder_outputs,\n",
    "        output_hidden_states=True,\n",
    "        return_dict_in_generate=True,\n",
    "        max_length=500,\n",
    "        min_length=10,\n",
    "        do_sample=True,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    # Retrieve generated token IDs and decode to text\n",
    "    generated_ids = outputs.sequences\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Collect the last decoder hidden states as embeddings, by Ziyue\n",
    "    last_column = [row[-1] for row in outputs.decoder_hidden_states]\n",
    "    decoder_embeddings = torch.stack(last_column).squeeze()  # squeeze() to eliminate unnecessary dimensions, prevent trouble when making alignment\n",
    "\n",
    "    # # Alternatively the code below achieve almost the same compared to the above two lines, by Boyue, this one has a better interpretation\n",
    "    # # They act exactly the same in T5 model, but different in BART (flips in dimensions)\n",
    "    # decoder_embeddings_2 = torch.cat(\n",
    "    #     [outputs.decoder_hidden_states[token_idx][-1] for token_idx in range(len(outputs.decoder_hidden_states))],\n",
    "    #     dim=1\n",
    "    # ).squeeze()\n",
    "    \n",
    "    # Decode embeddings back to tokens\n",
    "    decoded_tokens = [tokenizer.decode([token]) for token in generated_ids[0]]\n",
    "\n",
    "    return generated_text, decoder_embeddings, decoded_tokens\n",
    "\n",
    "def align_tensors(tensor_a: torch.Tensor, tensor_b: torch.Tensor, mode: str = \"truncate\") -> (torch.Tensor, torch.Tensor):\n",
    "    \"\"\"\n",
    "    Aligns two tensors along the first dimension by either truncating or padding.\n",
    "\n",
    "    Args:\n",
    "        tensor_a (torch.Tensor): The first tensor.\n",
    "        tensor_b (torch.Tensor): The second tensor.\n",
    "        mode (str): The alignment mode, either \"truncate\" or \"pad\".\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: The two tensors aligned along the first dimension.\n",
    "    \"\"\"\n",
    "    # Get the first dimension sizes\n",
    "    m, n = tensor_a.size(0), tensor_b.size(0)\n",
    "\n",
    "    if mode == \"truncate\":\n",
    "        # Truncate to the minimum length along the first dimension\n",
    "        min_rows = min(m, n)\n",
    "        tensor_a = tensor_a[:min_rows]\n",
    "        tensor_b = tensor_b[:min_rows]\n",
    "\n",
    "    elif mode == \"pad\":\n",
    "        # Pad to the maximum length along the first dimension\n",
    "        max_rows = max(m, n)\n",
    "        if m < max_rows:\n",
    "            padding = torch.zeros((max_rows - m, *tensor_a.shape[1:]), device=tensor_a.device)\n",
    "            tensor_a = torch.cat([tensor_a, padding], dim=0)\n",
    "        if n < max_rows:\n",
    "            padding = torch.zeros((max_rows - n, *tensor_b.shape[1:]), device=tensor_b.device)\n",
    "            tensor_b = torch.cat([tensor_b, padding], dim=0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'truncate' or 'pad'\")\n",
    "\n",
    "    return tensor_a, tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a89b036-8b99-46f9-8633-229bcd4afce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_text = 'hhh'\n",
    "# input_text = \"\"\"\n",
    "# Summarize the text: In telecommunications, orthogonal frequency-division multiplexing (OFDM) \n",
    "# is a type of digital transmission used in digital modulation for encoding digital (binary) data\n",
    "# on multiple carrier frequencies. OFDM has developed into a popular scheme for wideband digital \n",
    "# communication, used in applications such as digital television and audio broadcasting, DSL internet \n",
    "# access, wireless networks, power line networks, and 4G/5G mobile communications.\n",
    "# \"\"\".replace(\"\\n\", \"\")\n",
    "\n",
    "original_text = \"\"\"\n",
    "Beginners BBQ Class Taking Place in Missoula! \n",
    "Do you want to get better at making delicious BBQ?\n",
    "You will have the opportunity, put this on your calendar now. \n",
    "Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. \n",
    "He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. \n",
    "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. \n",
    "The cost to be in the class is $35 per person, and for spectators it is free. \n",
    "Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared. </s>\n",
    "\"\"\".replace(\"\\n\", \"\") \n",
    "input_text = \"\"\"\n",
    "Beginners BBQ Class Taking Place in Missoula! \n",
    "Do you want to get better at making delicious BBQ?\n",
    "You will have the opportunity, put this on your calendar now. \n",
    "Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. \n",
    "He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. \n",
    "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. \n",
    "The cost to be in the class is $35 per person, and for spectators it is free. \n",
    "Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
    "\"\"\".replace(\"\\n\", \"\")\n",
    "\n",
    "# original_text = \"\"\"\n",
    "# This November, embark on an exciting hiking adventure! \n",
    "# Explore the scenic mountain trails with an experienced guide, who will show you the best routes and hidden viewpoints. \n",
    "# This journey is suitable for all levels, from beginners to advanced hikers. \n",
    "# The hike covers approximately 10 miles and includes multiple rest stops with breathtaking views. \n",
    "# Participants should bring water, snacks, and comfortable hiking shoes. \n",
    "# The cost of the trip is $60, which includes a map and a group photo.\n",
    "# \"\"\".replace(\"\\n\", \"\") \n",
    "# input_text = \"\"\"\n",
    "# This November, embark on an exciting <mask> adventure! \n",
    "# Explore the scenic mountain trails with an experienced guide, who will show you the best routes and hidden <mask>. \n",
    "# This journey is suitable for all levels, from beginners to advanced <mask>. \n",
    "# The hike covers approximately 10 miles and includes multiple rest stops with breathtaking <mask>. \n",
    "# Participants should bring water, snacks, and comfortable hiking shoes. \n",
    "# The <mask> is $60, which includes a map and a group photo.\n",
    "# \"\"\".replace(\"\\n\", \"\")\n",
    "\n",
    "# original_text = \"\"\"\n",
    "# Welcome to our online coding bootcamp program! \n",
    "# Whether you're a complete beginner or looking to improve your programming skills, this course is designed for you. \n",
    "# Throughout the course, you will learn essential coding languages such as Python and JavaScript. \n",
    "# Our instructors will guide you through interactive projects and provide real-time feedback. \n",
    "# Each student will receive a certificate of completion at the end of the program. \n",
    "# The total cost for the bootcamp is $150, which includes all learning materials.\n",
    "# \"\"\".replace(\"\\n\", \"\") \n",
    "# input_text = \"\"\"\n",
    "# Welcome to our online <mask> bootcamp program! \n",
    "# Whether you're a complete beginner or looking to <mask> your programming skills, this course is designed for you. \n",
    "# Throughout the course, you will learn essential <mask> such as Python and JavaScript. \n",
    "# Our instructors will guide you through interactive projects and provide real-time <mask>. \n",
    "# Each student will receive a certificate of completion at the end of the <mask>. \n",
    "# The total cost for the bootcamp is $150, which <mask> all learning materials.\n",
    "# \"\"\".replace(\"\\n\", \"\") \n",
    "\n",
    "### </s> signaling the end of the text, better to add one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d5df8a-8f2c-424b-8b05-1cc7f5638596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Generated Text:\n",
      " Beginners BBQ Class Taking Place in Missoula! Do you want to get better at making delicious BBQ?You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared. </s>\n",
      "\n",
      "Baseline Generated Text:\n",
      " Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "\n",
      "Generated Text with Noise:\n",
      " Do you want to get better at making delicious BBQ? You will have the opportunity, Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers for a class.\n",
      "Average cosine similarity: 0.6111845970153809\n"
     ]
    }
   ],
   "source": [
    "target_snr = 0  # Define a target SNR for noise\n",
    "\n",
    "# Get encoder outputs\n",
    "with torch.no_grad():\n",
    "    if mode == 't5':\n",
    "        encoder_outputs = model.encoder(input_ids=tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device))\n",
    "    elif mode == 'bart':\n",
    "        encoder_outputs = model.model.encoder(input_ids=tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device))\n",
    "\n",
    "# Generate text with clean and noisy encoder outputs\n",
    "baseline_text, baseline_embeddings, baseline_tokens = generate_with_embeddings(input_text, encoder_outputs=encoder_outputs, mode=mode)\n",
    "\n",
    "# Generate with noisy encoder output\n",
    "noisy_encoder_output = add_noise_with_snr(encoder_outputs.last_hidden_state, target_snr)\n",
    "modified_encoder_outputs = BaseModelOutput(last_hidden_state=noisy_encoder_output)\n",
    "noisy_text, noisy_embeddings, noisy_tokens = generate_with_embeddings(input_text, encoder_outputs=modified_encoder_outputs)\n",
    "\n",
    "# # Display results\n",
    "print(\"Original Generated Text:\\n\", original_text)\n",
    "print(\"\\nBaseline Generated Text:\\n\", baseline_text)\n",
    "# print(\"Baseline Decoder Embeddings Shape:\", baseline_embeddings.shape)\n",
    "# print(\"Baseline Decoded Tokens:\", baseline_tokens)\n",
    "\n",
    "print(\"\\nGenerated Text with Noise:\\n\", noisy_text)\n",
    "# print(\"Noisy Decoder Embeddings Shape:\", noisy_embeddings.shape)\n",
    "# print(\"Noisy Decoded Tokens:\", noisy_tokens)\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "baseline_embeddings_aligned, noisy_embeddings_aligned = align_tensors(baseline_embeddings, noisy_embeddings, mode='pad')\n",
    "cosine_similarities = F.cosine_similarity(noisy_embeddings_aligned, baseline_embeddings_aligned, dim=-1)\n",
    "# print(\"Cosine similarities for each token:\", cosine_similarities)\n",
    "average_cosine_similarity = cosine_similarities.mean().item()\n",
    "print(\"Average cosine similarity:\", average_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd0579-e06f-40bf-835c-cf9496b7ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SNR range\n",
    "snr_range = list(range(-20, 21, 1)) + list(range(22, 61, 2)) + list(range(64, 101, 4))  # From -20 to 100, with different resolution\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Generate baseline (noise-free) encoder outputs\n",
    "with torch.no_grad():\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    if mode == 't5':\n",
    "        encoder_outputs = model.encoder(input_ids=tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device))\n",
    "    elif mode == 'bart':\n",
    "        encoder_outputs = model.model.encoder(input_ids=tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device))\n",
    "    \n",
    "# Generate baseline embeddings\n",
    "baseline_text, baseline_embeddings, baseline_tokens = generate_with_embeddings(input_text, encoder_outputs=encoder_outputs)\n",
    "\n",
    "# Iterate over SNR values and calculate cosine similarity for each\n",
    "for target_snr in tqdm(snr_range):\n",
    "    # Add noise to encoder outputs with the current SNR level\n",
    "    noisy_encoder_output = add_noise_with_snr(encoder_outputs.last_hidden_state, target_snr)\n",
    "    modified_encoder_outputs = BaseModelOutput(last_hidden_state=noisy_encoder_output)\n",
    "    \n",
    "    # Generate output embeddings with noisy encoder outputs\n",
    "    noisy_text, noisy_embeddings, noisy_tokens = generate_with_embeddings(input_text, encoder_outputs=modified_encoder_outputs)\n",
    "    \n",
    "    # Calculate cosine similarity for each token and then compute the average\n",
    "    baseline_embeddings_aligned, noisy_embeddings_aligned = align_tensors(baseline_embeddings, noisy_embeddings, mode='pad')\n",
    "    cosine_similarities = F.cosine_similarity(noisy_embeddings_aligned, baseline_embeddings_aligned, dim=-1)\n",
    "    average_cosine_similarity = cosine_similarities.mean().item()\n",
    "    cosine_similarities_list.append(average_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b5abb-fe65-4b7c-a086-b3128c86718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot of cosine similarity, example BART, truncate\n",
    "# plt.figure(figsize=(20, 6), dpi=300)\n",
    "# plt.plot(snr_range, cosine_similarities_list, marker='o')\n",
    "# plt.xlabel(\"SNR (dB)\")\n",
    "# plt.ylabel(\"Average Cosine Similarity\")\n",
    "# plt.title(\"Cosine Similarity vs SNR (BART)\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77feb61c-8061-4253-b029-f3a3b42389a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot of cosine similarity, example BART, pad\n",
    "# plt.figure(figsize=(20, 6), dpi=300)\n",
    "# plt.plot(snr_range, cosine_similarities_list, marker='o')\n",
    "# plt.xlabel(\"SNR (dB)\")\n",
    "# plt.ylabel(\"Average Cosine Similarity\")\n",
    "# plt.title(\"Cosine Similarity vs SNR (BART)\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70e674-53ed-4bb6-878b-740e260502fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot of cosine similarity, example flan-T5, truncate\n",
    "# plt.figure(figsize=(20, 6), dpi=300)\n",
    "# plt.plot(snr_range, cosine_similarities_list, marker='o')\n",
    "# plt.xlabel(\"SNR (dB)\")\n",
    "# plt.ylabel(\"Average Cosine Similarity\")\n",
    "# plt.title(\"Cosine Similarity vs SNR (flan-T5)\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b6879-8aab-4ab1-a5c9-0659a10d4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot of cosine similarity, example flan-T5, pad\n",
    "# plt.figure(figsize=(20, 6), dpi=300)\n",
    "# plt.plot(snr_range, cosine_similarities_list, marker='o')\n",
    "# plt.xlabel(\"SNR (dB)\")\n",
    "# plt.ylabel(\"Average Cosine Similarity\")\n",
    "# plt.title(\"Cosine Similarity vs SNR (flan-T5)\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
