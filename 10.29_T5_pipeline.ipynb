{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2261e128-1655-47ba-8e41-c6800f0b018f",
   "metadata": {},
   "source": [
    "## Use pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98addefa-bb25-4ee6-87f1-8462f84bcecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'In telecommunications, orthogonal frequency-division multiplexing (OFDM) is a type of digital transmission used in digital modulation for encoding digital (binary) dataon multiple carrier frequencies. OFDM has developed into a popular scheme for wideband digital communication, used in applications such as digital television and audio broadcasting, DSL internet access, wireless networks, power line networks, and 4G/5G mobile communications.'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "import torch\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize translation pipeline\n",
    "translator = pipeline(\"translation_en_to_de\", model=\"facebook/bart-base\", device=device)\n",
    "\n",
    "# input_text = \"My name is Ziyue and I live in Sweden.\"\n",
    "input_text = \"\"\"\n",
    "In telecommunications, orthogonal frequency-division multiplexing (OFDM) \n",
    "is a type of digital transmission used in digital modulation for encoding digital (binary) data\n",
    "on multiple carrier frequencies. OFDM has developed into a popular scheme for wideband digital \n",
    "communication, used in applications such as digital television and audio broadcasting, DSL internet \n",
    "access, wireless networks, power line networks, and 4G/5G mobile communications.\n",
    "\"\"\"\n",
    "\n",
    "output = translator(\n",
    "    input_text,\n",
    "    max_length=200,      # Adjust max length for summary\n",
    "    min_length=30,       # Adjust min length for summary\n",
    "    do_sample=True,      # Enables sampling for temperature to take effect\n",
    "    temperature=0.1,     # Controls the randomness\n",
    "    top_k=50,            # Limits sampling to top K most likely options\n",
    "    top_p=0.9            # Limits sampling to top cumulative probability P\n",
    ")\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f7c471-2124-480d-855a-db70117f44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Memory Allocated: 1710.58 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max Memory Allocated: {torch.cuda.max_memory_allocated(device) / 1024 ** 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df35de-62dc-4ff3-98f1-4d9630722776",
   "metadata": {},
   "source": [
    "## Pipeline + Noise (fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1996838e-e683-4fea-9c5c-e4d86791ae40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px;'>Original text: This is my first time visiting Berlin.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation result without noise:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px; font-family:\"Comic Sans MS\", cursive;'> I'm not sure if it's the same as the one I've been to in the past. I'm not sure if it's the same as the one I've been to in the past.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation result with added noise (SNR = 100 dB):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px; font-family:\"Comic Sans MS\", cursive;'> I'm not sure if it's the same as the one I've been to before, but I'm not sure. I'm not sure if it's the same as the one I've been to before, but I'm not sure.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "import torch\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize translation pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\", model=\"google/flan-t5-base\", device=device)\n",
    "\n",
    "# Get model and tokenizer\n",
    "model = translator.model.to(device)\n",
    "tokenizer = translator.tokenizer\n",
    "\n",
    "def add_noise_with_snr(encoder_output, target_snr_db):\n",
    "    \"\"\"\n",
    "    Add noise to the encoder output based on the target Signal-to-Noise Ratio (SNR).\n",
    "\n",
    "    Parameters:\n",
    "    - encoder_output: torch.Tensor, the output of the encoder (last_hidden_state).\n",
    "    - target_snr_db: float, the desired SNR (in dB).\n",
    "\n",
    "    Returns:\n",
    "    - noisy_encoder_output: torch.Tensor, the encoder output with added noise.\n",
    "    \"\"\"\n",
    "    # Convert SNR from dB to linear scale\n",
    "    target_snr_linear = 10 ** (target_snr_db / 10)\n",
    "    \n",
    "    # Calculate signal power\n",
    "    signal_power = torch.mean(encoder_output ** 2)\n",
    "    \n",
    "    # Calculate the noise power required to achieve the target SNR\n",
    "    noise_power = signal_power / target_snr_linear\n",
    "    noise = torch.randn_like(encoder_output) * torch.sqrt(noise_power)\n",
    "    \n",
    "    # Add noise to the encoder output\n",
    "    noisy_encoder_output = encoder_output + noise\n",
    "    return noisy_encoder_output\n",
    "\n",
    "input_text = \"This is my first time visiting Berlin.\"\n",
    "\n",
    "# Encode input text as input IDs\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# Get encoder output (without noise)\n",
    "with torch.no_grad():\n",
    "    encoder_outputs = model.encoder(input_ids=input_ids)\n",
    "\n",
    "# Generate translation using the noise-free encoder output\n",
    "baseline_outputs = model.generate(\n",
    "    input_ids=None,\n",
    "    encoder_outputs=encoder_outputs,\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    temperature=0.1\n",
    ")\n",
    "baseline_text = tokenizer.decode(baseline_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Add noise to the encoder output\n",
    "target_snr = 100  # Set target SNR\n",
    "noisy_encoder_output = add_noise_with_snr(encoder_outputs.last_hidden_state, target_snr)\n",
    "modified_encoder_outputs = BaseModelOutput(last_hidden_state=noisy_encoder_output)\n",
    "\n",
    "# Generate translation using the encoder output with added noise\n",
    "noisy_outputs = model.generate(\n",
    "    input_ids=None,\n",
    "    encoder_outputs=modified_encoder_outputs,\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    temperature=0.1\n",
    ")\n",
    "noisy_text = tokenizer.decode(noisy_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display results\n",
    "display(HTML(f\"<p style='font-size:15px;'>Original text: {input_text}</p>\"))\n",
    "print('Translation result without noise:')\n",
    "display(HTML(f\"<p style='font-size:20px; font-family:\\\"Comic Sans MS\\\", cursive;'> {baseline_text}</p>\"))\n",
    "print(f'Translation result with added noise (SNR = {target_snr} dB):')\n",
    "display(HTML(f\"<p style='font-size:20px; font-family:\\\"Comic Sans MS\\\", cursive;'> {noisy_text}</p>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e8486-b61d-4ff3-ab7f-55988c167f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0942d55a44c446e3b7099f4da84c2130": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "25166751ae38474eb1d091dcda0c9d08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2b8b2686b6974929832e71b4f080911a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_789068c7580c4507a68925406b72f8c2",
        "IPY_MODEL_abac78e111324c21bece4ff05015b821",
        "IPY_MODEL_ac474b7fcacc48d7b7ee810befc57dc3"
       ],
       "layout": "IPY_MODEL_d0fc28903a624a2092fde3a33ea8300b"
      }
     },
     "2ba9b04b19d247cab6c4d478648ffb4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3cf049133d714edfa4fb0d9ec40d7a9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_eceab9b1eb1b4d38bacf3c31b472ef26",
       "style": "IPY_MODEL_2ba9b04b19d247cab6c4d478648ffb4e",
       "value": " 2/2 [00:00&lt;00:00,  6.69it/s]"
      }
     },
     "46133a50065e46668f16c48e9bdc86d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e53567c6ae434a31b548118c9302ad6b",
       "style": "IPY_MODEL_f0b265cd2793467d9c9e42126a7131af",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "708c1922496e4633a645d5a7e6020e88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "789068c7580c4507a68925406b72f8c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cd2940c0dff548bc971636c33822dae9",
       "style": "IPY_MODEL_708c1922496e4633a645d5a7e6020e88",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "7b15686008fc4b94ba20f2126f5c0b5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8d09ef98198b4006b92716434427a0e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a12225407e8b435d8dc64a4900464c6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_46133a50065e46668f16c48e9bdc86d1",
        "IPY_MODEL_ca01b851bd5b407f8f67f08fe70937a4",
        "IPY_MODEL_3cf049133d714edfa4fb0d9ec40d7a9d"
       ],
       "layout": "IPY_MODEL_0942d55a44c446e3b7099f4da84c2130"
      }
     },
     "abac78e111324c21bece4ff05015b821": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_25166751ae38474eb1d091dcda0c9d08",
       "max": 2,
       "style": "IPY_MODEL_7b15686008fc4b94ba20f2126f5c0b5b",
       "value": 2
      }
     },
     "ac474b7fcacc48d7b7ee810befc57dc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fd9a7aace270416b84e6369ceebc5659",
       "style": "IPY_MODEL_e8fc6fdfc88b472a86907ddf84994587",
       "value": " 2/2 [00:00&lt;00:00,  8.13it/s]"
      }
     },
     "c81dea55e3ce4c1cbe5692aeaf3bf29c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ca01b851bd5b407f8f67f08fe70937a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c81dea55e3ce4c1cbe5692aeaf3bf29c",
       "max": 2,
       "style": "IPY_MODEL_8d09ef98198b4006b92716434427a0e6",
       "value": 2
      }
     },
     "cd2940c0dff548bc971636c33822dae9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d0fc28903a624a2092fde3a33ea8300b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e53567c6ae434a31b548118c9302ad6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e8fc6fdfc88b472a86907ddf84994587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eceab9b1eb1b4d38bacf3c31b472ef26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f0b265cd2793467d9c9e42126a7131af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fd9a7aace270416b84e6369ceebc5659": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
