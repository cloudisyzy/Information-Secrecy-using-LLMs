{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51d19bc-5cdb-4d61-a831-149ff23dda58",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2d7f97-3409-4db2-8b0c-63f60e5bdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from IPython.display import display, HTML\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28daa6cc-0262-4883-bcc5-b814094deee5",
   "metadata": {},
   "source": [
    "## 2. Choose Device (GPU / CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848e40a3-465b-4b80-97a5-bbf5d7ec9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically choose (prefer NVIDIA GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # OR choose device manually, be sure to comment other codes relevant to `device`\n",
    "# device = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407a986-60e0-40da-8012-69cfb9daa8ef",
   "metadata": {},
   "source": [
    "## 3. Load BART model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85eeac8-f09a-40e8-b962-00bbb37029a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model name\n",
    "# model_name = \"facebook/bart-base\"\n",
    "model_name = \"facebook/bart-large\" # Recommend this one if your computer is okay with larger models\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9d40d-867c-4d40-98c6-01ce5cbb4ee6",
   "metadata": {},
   "source": [
    "## 4. A function adding AWGN noise to latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51e5db1-20a2-402f-8970-412c1adcc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(encoder_output, target_snr_db):\n",
    "    \"\"\"\n",
    "    Add noise to the encoder output based on a target SNR in dB.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoder_output: torch.Tensor, the encoder's output (last_hidden_state).\n",
    "    - target_snr_db: float, the desired signal-to-noise ratio in dB.\n",
    "    \n",
    "    Returns:\n",
    "    - noisy_encoder_output: torch.Tensor, encoder output with added noise.\n",
    "    \"\"\"\n",
    "    # Convert SNR from dB to linear scale\n",
    "    target_snr_linear = 10 ** (target_snr_db / 10)\n",
    "    \n",
    "    # Calculate power of the signal\n",
    "    signal_power = torch.mean(encoder_output ** 2)\n",
    "    \n",
    "    # Calculate required noise power for the target SNR\n",
    "    noise_power = signal_power / target_snr_linear\n",
    "    noise = torch.randn_like(encoder_output) * torch.sqrt(noise_power)\n",
    "    \n",
    "    # Add noise to the encoder output\n",
    "    noisy_encoder_output = encoder_output + noise\n",
    "    return noisy_encoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9e65a-369d-4756-8a0f-de2697a24ec0",
   "metadata": {},
   "source": [
    "## 5. Three example encoder inputs for `fill in the blank` task\n",
    "\n",
    "`original_text` contains the complete text <br>\n",
    "`input_text` contains the masked text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e9cbd8-7d87-454a-a185-f996aea851a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"\"\"\n",
    "Beginners BBQ Class Taking Place in Missoula! \n",
    "Do you want to get better at making delicious BBQ?\n",
    "You will have the opportunity, put this on your calendar now. \n",
    "Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. \n",
    "He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. \n",
    "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. \n",
    "The cost to be in the class is $35 per person, and for spectators it is free. \n",
    "Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
    "\"\"\"\n",
    "input_text = \"\"\"\n",
    "Beginners BBQ Class <mask> in Missoula! \n",
    "Do you want to <mask> making delicious BBQ?\n",
    "You will have the opportunity, put this on your calendar now. \n",
    "Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. \n",
    "He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. \n",
    "He will teach you <mask> compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. \n",
    "The <mask> the class is $35 per person, and for spectators it is free. \n",
    "Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
    "\"\"\".replace(\"\\n\", \"\")\n",
    "\n",
    "# original_text = \"\"\"\n",
    "# This November, embark on an exciting hiking adventure! \n",
    "# Explore the scenic mountain trails with an experienced guide, who will show you the best routes and hidden viewpoints. \n",
    "# This journey is suitable for all levels, from beginners to advanced hikers. \n",
    "# The hike covers approximately 10 miles and includes multiple rest stops with breathtaking views. \n",
    "# Participants should bring water, snacks, and comfortable hiking shoes. \n",
    "# The cost of the trip is $60, which includes a map and a group photo.\n",
    "# \"\"\"\n",
    "# input_text = \"\"\"\n",
    "# This November, embark on an exciting <mask> adventure! \n",
    "# Explore the scenic mountain trails with an experienced guide, who will show you the best routes and hidden <mask>. \n",
    "# This journey is suitable for all levels, from beginners to advanced <mask>. \n",
    "# The hike covers approximately 10 miles and includes multiple rest stops with breathtaking <mask>. \n",
    "# Participants should bring water, snacks, and comfortable hiking shoes. \n",
    "# The <mask> is $60, which includes a map and a group photo.\n",
    "# \"\"\".replace(\"\\n\", \"\")\n",
    "\n",
    "# original_text = \"\"\"\n",
    "# Welcome to our online coding bootcamp program! \n",
    "# Whether you're a complete beginner or looking to improve your programming skills, this course is designed for you. \n",
    "# Throughout the course, you will learn essential coding languages such as Python and JavaScript. \n",
    "# Our instructors will guide you through interactive projects and provide real-time feedback. \n",
    "# Each student will receive a certificate of completion at the end of the program. \n",
    "# The total cost for the bootcamp is $150, which includes all learning materials.\n",
    "# \"\"\"\n",
    "# input_text = \"\"\"\n",
    "# Welcome to our online <mask> bootcamp program! \n",
    "# Whether you're a complete beginner or looking to <mask> your programming skills, this course is designed for you. \n",
    "# Throughout the course, you will learn essential <mask> such as Python and JavaScript. \n",
    "# Our instructors will guide you through interactive projects and provide real-time <mask>. \n",
    "# Each student will receive a certificate of completion at the end of the <mask>. \n",
    "# The total cost for the bootcamp is $150, which <mask> all learning materials.\n",
    "# \"\"\".replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f564705-e573-4b22-84ef-5ad1cc7f388b",
   "metadata": {},
   "source": [
    "## 6. Pass the `input_text` through the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9827c3-f755-4d38-9971-6a6e852d533c",
   "metadata": {},
   "source": [
    "### 6.1 Tokenize the `input_text` to tokens (integer numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926fccb3-486f-4a8d-b1fe-96b2f7db1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b45b84-6279-473d-a3e7-090e330cf77c",
   "metadata": {},
   "source": [
    "### 6.2 Get encoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ac6e70-871e-45d8-bca4-e4eed844318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoder_outputs = model.model.encoder(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e647e1-0462-40fc-8784-3f9400efa3b2",
   "metadata": {},
   "source": [
    "### 6.3.1 Case 1: clean latent reprenstation (without noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beff5010-1fb3-40d0-974e-cfbda554b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate output with the clean encoder output (latent reprenstation)\n",
    "baseline_outputs = model.generate(\n",
    "    input_ids=None,                   # No input tokens are provided here, as we're feeding encoder outputs directly\n",
    "    encoder_outputs=encoder_outputs,  # Encoded representations from the encoder\n",
    "    max_length=200,                   # Set maximum length for the generated text sequence\n",
    "    min_length=10,                    # Set minimum length for the generated text sequence\n",
    "    do_sample=True,                   # Enables sampling for diverse outputs, rather than greedy decoding\n",
    "    temperature=0.1                   # Low temperature to control randomness, resulting in less varied output\n",
    ")\n",
    "\n",
    "# Decode the decoder output using tokenizer\n",
    "baseline_text = tokenizer.decode(baseline_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f0040-8eab-4f69-9a55-d3829221d684",
   "metadata": {},
   "source": [
    "### 6.3.2 Case 2: noisy latent reprenstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db3c398-8dfd-45c8-a37e-e9757be87682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise with a target SNR and generate noisy output (latent reprenstation)\n",
    "target_snr = 3  # Set target SNR\n",
    "noisy_encoder_output = add_noise_with_snr(encoder_outputs.last_hidden_state, target_snr) # Add noise\n",
    "modified_encoder_outputs = BaseModelOutput(last_hidden_state=noisy_encoder_output) # There are slight differences between `noisy_encoder_output` and `modified_encoder_outputs`, print them for more info\n",
    "\n",
    "# Generate output with the noisy encoder output\n",
    "noisy_outputs = model.generate(\n",
    "    input_ids=None,                            # No input tokens are provided here, as we're feeding encoder outputs directly\n",
    "    encoder_outputs=modified_encoder_outputs,  # Encoded representations from the encoder\n",
    "    max_length=200,                            # Set maximum length for the generated text sequence\n",
    "    min_length=10,                             # Set minimum length for the generated text sequence\n",
    "    do_sample=True,                            # Enables sampling for diverse outputs, rather than greedy decoding\n",
    "    temperature=0.1                            # Low temperature to control randomness, resulting in less varied output\n",
    ")\n",
    "\n",
    "# Decode the decoder output using tokenizer\n",
    "noisy_text = tokenizer.decode(noisy_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97911c-af4d-4c32-8a3e-5ee1b1cbcb10",
   "metadata": {},
   "source": [
    "## 7. Display original texts and both outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496494de-2611-44ab-b11d-1cd340947e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px; font-family:\"Comic Sans MS\", cursive;'> \n",
       "Beginners BBQ Class Taking Place in Missoula! \n",
       "Do you want to get better at making delicious BBQ?\n",
       "You will have the opportunity, put this on your calendar now. \n",
       "Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. \n",
       "He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. \n",
       "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information. \n",
       "The cost to be in the class is $35 per person, and for spectators it is free. \n",
       "Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Without Noise:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px; font-family:\"Comic Sans MS\", cursive;'>Beginners BBQ Class at Lonestar Smoke Rangers in Missoula!Do you love BBQ? Do you want to learn how to cook it? Are you interested in making delicious BBQ?You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from LonestAR Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills. The cost to attend the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.Tony will give you the basics of how to prepare and compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "With Noise (SNR = 3 dB):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='font-size:15px; font-family:\"Comic Sans MS\", cursive;'>Beginners BBQ Class in Missoula!× Beginner BBQ Class at Lonestar Smoke Rangers BBQ in Missa’s on September 22nd!There will be a beginners BBQ class in Missou'a this Thursday in Missana's Lonesta Smoke-Rests in Missan’a in Misso’, in the Lonestas Smoke-Trap in Missusa. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.Do you want to learn more about making delicious BBQ?You will have the opportunity, put this on your calendar now. The cost to attend the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared. He’ll be teaching us how to compete in a KCBS BBQ competition competition, including techniques, recipes</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original Text:')\n",
    "display(HTML(f\"<p style='font-size:15px; font-family:\\\"Comic Sans MS\\\", cursive;'> {original_text}</p>\"))\n",
    "print('\\n')\n",
    "\n",
    "print('Without Noise:')\n",
    "display(HTML(f\"<p style='font-size:15px; font-family:\\\"Comic Sans MS\\\", cursive;'>{baseline_text}</p>\"))\n",
    "print('\\n')\n",
    "\n",
    "print(f'With Noise (SNR = {target_snr} dB):')\n",
    "display(HTML(f\"<p style='font-size:15px; font-family:\\\"Comic Sans MS\\\", cursive;'>{noisy_text}</p>\"))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe92d5e-a040-4839-bdf6-eb9fb3a20e6b",
   "metadata": {},
   "source": [
    "## You can also display some of the variables you find interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1881517c-b85f-40b0-9ce7-eccd84f6a08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 48290,  7130, 22658,  4210, 50264,    11,  4523,  5156,   102,\n",
      "           328,  1832,    47,   236,     7, 50264,   442, 10964, 22658,   116,\n",
      "          1185,    40,    33,     5,   945,     6,   342,    42,    15,   110,\n",
      "          7127,   122,     4,   296,     6,   772,   820,  1187,  1962,   623,\n",
      "          4210, 22658, 10078,     6,  3621,  4317,   857,    31,   226, 28180,\n",
      "           271, 21389,  5706,     4,    91,    40,    28,  5307,    10, 37239,\n",
      "           672,  1380,    13,   961,    54,  1072,     7,   120,   357,    19,\n",
      "            49, 16820,  2417,     4,    91,    40,  6396,    47, 50264,  3511,\n",
      "            11,    10,   229,  8949, 22658,  1465,     6,   217,  7373,     6,\n",
      "         13204,     6, 31583,     6,  4884,  4230,     8, 10723,  7059,     6,\n",
      "          2704, 40345,     8,   668,   335,     4,    20, 50264,     5,  1380,\n",
      "            16,    68,  2022,   228,   621,     6,     8,    13, 17596,    24,\n",
      "            16,   481,     4, 30411,    11,     5,   701,    40,    28,  1169,\n",
      "            10,   326,    12,  8674,    50,    10, 26404,     8,    47,    40,\n",
      "            28, 18469,  7931,     9,   349,  4884,    14,    16,  2460,     4,\n",
      "             2]], device='cuda:0')\n",
      "torch.Size([1, 151])\n"
     ]
    }
   ],
   "source": [
    "# `input_text` after tokenization\n",
    "print(input_ids)\n",
    "\n",
    "# its shape\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a707210-a71d-4c53-9c2d-611f8dabb6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[ 1.7068e-03,  3.7224e-02,  2.8920e-02,  ...,  3.5600e-03,\n",
      "           7.9942e-03, -3.4197e-04],\n",
      "         [ 1.6971e-01,  1.2020e-01,  3.8075e-02,  ..., -1.9527e-01,\n",
      "          -5.2274e-02,  2.9820e-02],\n",
      "         [ 5.0318e-02,  6.8451e-02,  5.2653e-01,  ...,  2.0947e-02,\n",
      "          -2.6133e-01,  1.0611e-01],\n",
      "         ...,\n",
      "         [-3.0117e-02, -5.0357e-01, -2.2870e-01,  ..., -1.3845e-01,\n",
      "          -9.2816e-02,  6.2812e-02],\n",
      "         [ 7.6866e-04,  1.6385e-02,  6.8835e-03,  ...,  4.4163e-03,\n",
      "          -5.5813e-03, -1.0422e-03],\n",
      "         [ 1.1516e-01,  2.9140e-01,  6.6931e-02,  ..., -3.7684e-02,\n",
      "          -8.0240e-02,  4.4079e-02]],\n",
      "\n",
      "        [[ 1.7068e-03,  3.7224e-02,  2.8920e-02,  ...,  3.5600e-03,\n",
      "           7.9942e-03, -3.4197e-04],\n",
      "         [ 1.6971e-01,  1.2020e-01,  3.8075e-02,  ..., -1.9527e-01,\n",
      "          -5.2274e-02,  2.9820e-02],\n",
      "         [ 5.0318e-02,  6.8451e-02,  5.2653e-01,  ...,  2.0947e-02,\n",
      "          -2.6133e-01,  1.0611e-01],\n",
      "         ...,\n",
      "         [-3.0117e-02, -5.0357e-01, -2.2870e-01,  ..., -1.3845e-01,\n",
      "          -9.2816e-02,  6.2812e-02],\n",
      "         [ 7.6866e-04,  1.6385e-02,  6.8835e-03,  ...,  4.4163e-03,\n",
      "          -5.5813e-03, -1.0422e-03],\n",
      "         [ 1.1516e-01,  2.9140e-01,  6.6931e-02,  ..., -3.7684e-02,\n",
      "          -8.0240e-02,  4.4079e-02]],\n",
      "\n",
      "        [[ 1.7068e-03,  3.7224e-02,  2.8920e-02,  ...,  3.5600e-03,\n",
      "           7.9942e-03, -3.4197e-04],\n",
      "         [ 1.6971e-01,  1.2020e-01,  3.8075e-02,  ..., -1.9527e-01,\n",
      "          -5.2274e-02,  2.9820e-02],\n",
      "         [ 5.0318e-02,  6.8451e-02,  5.2653e-01,  ...,  2.0947e-02,\n",
      "          -2.6133e-01,  1.0611e-01],\n",
      "         ...,\n",
      "         [-3.0117e-02, -5.0357e-01, -2.2870e-01,  ..., -1.3845e-01,\n",
      "          -9.2816e-02,  6.2812e-02],\n",
      "         [ 7.6866e-04,  1.6385e-02,  6.8835e-03,  ...,  4.4163e-03,\n",
      "          -5.5813e-03, -1.0422e-03],\n",
      "         [ 1.1516e-01,  2.9140e-01,  6.6931e-02,  ..., -3.7684e-02,\n",
      "          -8.0240e-02,  4.4079e-02]],\n",
      "\n",
      "        [[ 1.7068e-03,  3.7224e-02,  2.8920e-02,  ...,  3.5600e-03,\n",
      "           7.9942e-03, -3.4197e-04],\n",
      "         [ 1.6971e-01,  1.2020e-01,  3.8075e-02,  ..., -1.9527e-01,\n",
      "          -5.2274e-02,  2.9820e-02],\n",
      "         [ 5.0318e-02,  6.8451e-02,  5.2653e-01,  ...,  2.0947e-02,\n",
      "          -2.6133e-01,  1.0611e-01],\n",
      "         ...,\n",
      "         [-3.0117e-02, -5.0357e-01, -2.2870e-01,  ..., -1.3845e-01,\n",
      "          -9.2816e-02,  6.2812e-02],\n",
      "         [ 7.6866e-04,  1.6385e-02,  6.8835e-03,  ...,  4.4163e-03,\n",
      "          -5.5813e-03, -1.0422e-03],\n",
      "         [ 1.1516e-01,  2.9140e-01,  6.6931e-02,  ..., -3.7684e-02,\n",
      "          -8.0240e-02,  4.4079e-02]]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "torch.Size([4, 151, 1024])\n"
     ]
    }
   ],
   "source": [
    "# latent representation (context vectors)\n",
    "print(encoder_outputs)\n",
    "\n",
    "# its shape\n",
    "print(encoder_outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c98b468-42aa-445d-bfb7-a268e4f939da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     0, 48290,  7130, 22658,  4210,    23,   226, 28180,   271,\n",
      "         21389,  5706,    11,  4523,  5156,   102,   328,  8275,    47,   657,\n",
      "         22658,   116,  1832,    47,   236,     7,  1532,   141,     7,  7142,\n",
      "            24,   116,  3945,    47,  2509,    11,   442, 10964, 22658,   116,\n",
      "          1185,    40,    33,     5,   945,     6,   342,    42,    15,   110,\n",
      "          7127,   122,     4,   296,     6,   772,   820,  1187,  1962,   623,\n",
      "          4210, 22658, 10078,     6,  3621,  4317,   857,    31,   226, 28180,\n",
      "          2747, 21389,  5706,     4,    91,    40,    28,  5307,    10, 37239,\n",
      "           672,  1380,    13,   961,    54,  1072,     7,   120,   357,    19,\n",
      "            49, 16820,  2417,     4,    20,   701,     7,  2725,     5,  1380,\n",
      "            16,    68,  2022,   228,   621,     6,     8,    13, 17596,    24,\n",
      "            16,   481,     4, 30411,    11,     5,   701,    40,    28,  1169,\n",
      "            10,   326,    12,  8674,    50,    10, 26404,     8,    47,    40,\n",
      "            28, 18469,  7931,     9,   349,  4884,    14,    16,  2460,     4,\n",
      "         26156,    40,   492,    47,     5, 17293,     9,   141,     7,  3886,\n",
      "             8,  3511,    11,    10,   229,  8949, 22658,  1465,     6,   217,\n",
      "          7373,     6, 13204,     6, 31583,     6,  4884,  4230,     8, 10723,\n",
      "          7059,     6,  2704, 40345,     8,   668,   335,     4,     2]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 179])\n"
     ]
    }
   ],
   "source": [
    "# The output of decoder before tokenization\n",
    "print(baseline_outputs)\n",
    "\n",
    "# its shape\n",
    "print(baseline_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e579a-ff0a-4657-b11f-ba9d1dfdc9c2",
   "metadata": {},
   "source": [
    "## How `tokenizer` works\n",
    "Since we will be likely use the `Falconsai/text_summarization` model as our text summarizer. It is better to explore the tokenizer for T5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c068016-d31a-40e9-bf0d-f1048d7adc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer for T5\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer_Fal = AutoTokenizer.from_pretrained(\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3254957b-b014-403f-9212-ae75c35206e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am a Master's student in Information and Networking Engineering at KTH.\"\n",
    "\n",
    "# Tokenize the above text\n",
    "tokenized_text = tokenizer_Fal(text, return_tensors=\"pt\")\n",
    "\n",
    "# By decoding the tokenized text you reconstruct the original text\n",
    "decoded_text = tokenizer_Fal.decode(tokenized_text['input_ids'][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476623c5-c064-46b3-8587-c14e1ea904b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a Master's student in Information and Networking Engineering at KTH.\n",
      "tensor([  27,  183,    3,    9, 3226,   31,    7, 1236,   16, 2784,   11, 3426,\n",
      "          53, 5623,   44,  480, 4611,    5,    1])\n",
      "I am a Master's student in Information and Networking Engineering at KTH.\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(tokenized_text['input_ids'][0])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84a153b4-6baf-4e82-a27c-951a52becad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", all a Master's student in Information and Networking Engineering at KTH. below\n"
     ]
    }
   ],
   "source": [
    "# Changing the values of tokenized_text with change the decoded text\n",
    "tokenized_text['input_ids'][0][0] = 6\n",
    "tokenized_text['input_ids'][0][1] = 66\n",
    "tokenized_text['input_ids'][0][-1] = 666\n",
    "decoded_text_1 = tokenizer_Fal.decode(tokenized_text['input_ids'][0], skip_special_tokens=True)\n",
    "print(decoded_text_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
